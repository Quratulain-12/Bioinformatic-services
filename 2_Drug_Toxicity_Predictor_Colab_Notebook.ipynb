{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzQ18po7LpiqxgeXC2RP3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quratulain-12/Bioinformatic-services/blob/main/2_Drug_Toxicity_Predictor_Colab_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JYVAbJ-C0_A0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drug Toxicity Predictor\n",
        "# Machine Learning model for toxicity prediction\n",
        "# @title Drug Toxicity Prediction Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"ðŸ’Š DRUG TOXICITY PREDICTION MODEL\")\n",
        "\n",
        "# @markdown Enter SMILES strings (comma separated):\n",
        "smiles_input = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C, CC(=O)OC1=CC=CC=C1C(=O)O\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown Select model parameters:\n",
        "n_estimators = 100 # @param {type:\"slider\", min:10, max:200, step:10}\n",
        "test_size = 0.2 # @param {type:\"slider\", min:0.1, max:0.5, step:0.05}\n",
        "\n",
        "# Load dataset (using sample Tox21 dataset)\n",
        "# In practice, you'd use ChEMBL or PubChem data\n",
        "!wget -q https://raw.githubusercontent.com/chemplexity/challenges/master/nih.csv\n",
        "df = pd.read_csv('nih.csv')\n",
        "\n",
        "# Preprocessing\n",
        "X = df.drop(['smiles', 'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER',\n",
        "             'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE',\n",
        "             'SR-MMP', 'SR-p53'], axis=1)\n",
        "y = df['SR-ARE']  # Stress response pathway indicator\n",
        "\n",
        "# Train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=42\n",
        ")\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=n_estimators)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"ðŸ“ˆ Model Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Non-Toxic', 'Toxic'],\n",
        "            yticklabels=['Non-Toxic', 'Toxic'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Prediction for user input\n",
        "def smiles_to_features(smiles):\n",
        "    \"\"\"Simplified feature extraction - real projects use RDKit\"\"\"\n",
        "    return [len(smiles), smiles.count('O'), smiles.count('N'),\n",
        "            smiles.count('Cl'), int('C' in smiles)]\n",
        "\n",
        "user_smiles = [s.strip() for s in smiles_input.split(',')]\n",
        "user_features = [smiles_to_features(s) for s in user_smiles]\n",
        "\n",
        "predictions = model.predict(user_features)\n",
        "toxicity_results = dict(zip(user_smiles, ['Toxic' if p == 1 else 'Non-Toxic' for p in predictions]))\n",
        "\n",
        "print(\"\\nðŸ”¬ PREDICTION RESULTS:\")\n",
        "for smiles, result in toxicity_results.items():\n",
        "    print(f\"{smiles}: {result}\")"
      ],
      "metadata": {
        "id": "9XxuqMoB1r2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}